---
---
@inproceedings{exploringmt,
selected = true,
img={/assets/img/ipaper2.png},
author = {Dwivedi, Utkarsh and Gandhi, Jaina and Parikh, Raj and Coenraad, Merijke and Bonsignore, Elizabeth and Kacorri, Hernisa },
title = {Exploring Machine Teaching with Children},
year = {2021},
isbn = {9781450334907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org/10.1145/2830629.2835223},
doi = {10.1145/2830629.2835223},
abstract = {Iteratively building and testing machine learning models can help children develop creativity, flexibility, and comfort with machine learning and artificial intelligence. 
We explore how children use machine teaching interfaces with a team of 14 children (aged 7-13 years) and adult co-designers.
Children trained image classifiers and tested each other's models for robustness. 
Our study illuminates how children reason about ML concepts, offering these insights for designing machine teaching experiences for children: (i) ML metrics (\eg confidence scores) should be visible for experimentation; (ii) ML activities should enable children to exchange models for promoting reflection and pattern recognition; and (iii) the interface should allow quick data inspection (\eg images vs. gestures).},
booktitle = {Proceedings of the 2021 IEEE Symposium on Visual Languages and Human-Centric Computing},
pages = {79–80},
numpages = {2},
keywords = {latent dirichlet allocation, environmental compliance, text mining},
location = {London, United Kingdom},
series = {VLHCC '21}
}

@inproceedings{sharingdata,
selected = true,
img={/assets/img/inclusetproject.png},
author = {Kamikubo, Rie and Dwivedi, Utkarsh and Hernisa Kacorri},
title = {Sharing Practices for Datasets Related to Wellness, Accessibility, and Aging},
year = {2021},
isbn = {9781450334907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org/10.1145/2830629.2835223},
abstract = {Datasets sourced from people with disabilities and older adults play an important role in innovation,
benchmarking, and mitigating bias for both assistive and inclusive AI-infused applications. However, they are scarce. We conduct a systematic review of 137 accessibility datasets manually located across different disciplines over the last 35 years. Our analysis highlights how researchers navigate tensions between benefits and risks in data collection and sharing. We uncover patterns in data collection purpose, terminology, sample size, data types, and data sharing practices across  communities of focus. We conclude by critically reflecting on challenges and opportunities related to locating and sharing accessibility datasets calling for technical, legal, and institutional privacy frameworks that are more attuned to concerns from these communities.},
doi = {10.1145/2830629.2835223},
booktitle = {Proceedings of the 2021 International ACM SIGACCESS Conference on Computers and Accessibility},
pages = {79–80},
numpages = {2},
keywords = {latent dirichlet allocation, environmental compliance, text mining},
location = {London, United Kingdom},
series = {ASSETS '21}
}

@inproceedings{compliance,
img={/assets/img/compliance.png},
author = {Dwivedi, Utkarsh and Dasgupta, Anirban},
title = {Enabling Compliance of Environmental Conditions},
year = {2015},
isbn = {9781450334907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org/10.1145/2830629.2835223},
doi = {10.1145/2830629.2835223},
abstract = {Industrial projects in India have to agree to specific sets of environmental conditions in order to function. Lack of compliance with these conditions results both in irreversible damage to the local environment as well as conflicts among the industry and the local community. Our aim is to provide a system that raises general awareness in the local community about the environmental conditions in vogue among the nearby industries so that compliance violations can be reported early on. We outline work in progress to mine the text of the clearance conditions and build a searchable mapping system that can answer various queries about these conditions.},
booktitle = {Proceedings of the 2015 Annual Symposium on Computing for Development},
pages = {79–80},
numpages = {2},
keywords = {latent dirichlet allocation, environmental compliance, text mining},
location = {London, United Kingdom},
series = {DEV '15}
}

@article{vocab,
  title={Using a Common Sense Knowledge Base to Auto Generate Multi-Dimensional Vocabulary Assessments.},
  author={Sharma Mittal, Ruhi and Nagar, Seema and Sharma, Mourvi and \textbf{Utkarsh, Dwivedi} and Dey, Prasenjit and Kokku, Ravi},
  journal={International Educational Data Mining Society},
  year={2018},
  publisher={ERIC}
}

@inproceedings{EyamKayo,
author = {\textbf{Utkarsh, Dwivedi} and Ahuja, Karan and Islam, Rahul and Barbhuiya, Ferdous A. and Nagar, Seema and Dey, Kuntal},
title = {EyamKayo: Interactive Gaze and Facial Expression Captcha},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038266},
doi = {10.1145/3030024.3038266},
abstract = {This paper introduces {it EyamKayo}, a first-of-its-kind interactive CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart), using eye gaze and facial expression based human interactions, to better distinguish humans from software robots. Our system generates a sequence of instructions, asking the user to follow a controlled sequence of gaze points, and generate a controlled sequence of facial expressions. We evaluate user comfort and system usability, and validate using usability tests.},
booktitle = {Proceedings of the 2017 International Conference on Intelligent User Interfaces Companion},
pages = {53–56},
numpages = {4},
keywords = {gaze, facial expression, interactive captcha, emotion},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@misc{veit2015optimizing,
      title={On Optimizing Human-Machine Task Assignments}, 
      author={Andreas Veit and Michael Wilber and Rajan Vaish and Serge Belongie and James Davis and Vishal Anand and Anshu Aviral and Prithvijit Chakrabarty and Yash Chandak and Sidharth Chaturvedi and Chinmaya Devaraj and Ankit Dhall and \textbf{Utkarsh Dwivedi} and Sanket Gupte and Sharath N. Sridhar and Karthik Paga and Anuj Pahuja and Aditya Raisinghani and Ayush Sharma and Shweta Sharma and Darpana Sinha and Nisarg Thakkar and K. Bala Vignesh and Utkarsh Verma and Kanniganti Abhishek and Amod Agrawal and Arya Aishwarya and Aurgho Bhattacharjee and Sarveshwaran Dhanasekar and Venkata Karthik Gullapalli and Shuchita Gupta and Chandana G and Kinjal Jain and Simran Kapur and Meghana Kasula and Shashi Kumar and Parth Kundaliya and Utkarsh Mathur and Alankrit Mishra and Aayush Mudgal and Aditya Nadimpalli and Munakala Sree Nihit and Akanksha Periwal and Ayush Sagar and Ayush Shah and Vikas Sharma and Yashovardhan Sharma and Faizal Siddiqui and Virender Singh and Abhinav S. and Anurag. D. Yadav},
      year={2015},
      eprint={1509.07543},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@inproceedings{notecode,
author = {Kumar, Vishesh and Dargan, Tuhina and \textbf{Utkarsh, Dwivedi} and Vijay, Poorvi},
title = {Note Code: A Tangible Music Programming Puzzle Tool},
year = {2015},
isbn = {9781450333054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2677199.2688817},
doi = {10.1145/2677199.2688817},
abstract = {We present the design of Note Code -- a music programming puzzle game designed as a tangible device coupled with a Graphical User Interface (GUI). Tapping patterns and placing boxes in proximity enables programming these "note-boxes" to store sets of notes, play them back and activate different sub-components or neighboring boxes. This system provides users the opportunity to learn a variety of computational concepts, including functions, function calling and recursion, conditionals, as well as engage in composing music. The GUI adds a dimension of viewing the created programs and interacting with a set of puzzles that help discover the various computational concepts in the pursuit of creating target tunes, and optimizing the program made.},
booktitle = {Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {625–629},
numpages = {5},
keywords = {tangible interaction, constructionism, puzzle based learning, education, tangible music, computational thinking},
location = {Stanford, California, USA},
series = {TEI '15}
}

@inproceedings{Incluset,
img={/assets/img/incluset.png},
author = {Kacorri, Hernisa and Dwivedi, Utkarsh and Amancherla, Sravya and Jha, Mayanka and Chanduka, Riya},
title = {IncluSet: A Data Surfacing Repository for Accessibility Datasets},
year = {2020},
isbn = {9781450371032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373625.3418026},
doi = {10.1145/3373625.3418026},
abstract = { Datasets and data sharing play an important role for innovation, benchmarking, mitigating bias, and understanding the complexity of real world AI-infused applications. However, there is a scarcity of available data generated by people with disabilities with the potential for training or evaluating machine learning models. This is partially due to smaller populations, disparate characteristics, lack of expertise for data annotation, as well as privacy concerns. Even when data are collected and are publicly available, it is often difficult to locate them. We present a novel data surfacing repository, called IncluSet, that allows researchers and the disability community to discover and link accessibility datasets. The repository is pre-populated with information about 139 existing datasets: 65 made publicly available, 25 available upon request, and 49 not shared by the authors but described in their manuscripts. More importantly, IncluSet is designed to expose existing and new dataset contributions so they may be discoverable through Google Dataset Search.},
booktitle = {Proceedings of the 2020 International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {72},
numpages = {4},
keywords = {repository, disability, dataset, bias, artificial intelligence},
location = {Virtual Event, Greece},
series = {ASSETS '20}
}

@inproceedings{datasharing,
img={/assets/img/dataset_examples.png},
author = {Kacorri, Hernisa and Dwivedi, Utkarsh and Kamikubo, Rie },
title = {Data Sharing in Wellness, Accessibility, and Aging},
abstract = {Curation and sharing of datasets are crucial for innovation, benchmarking, bias mitigation, and understanding of real-word scenarios, where AI-infused applica-tions are deployed. This is especially the case for datasets from underrepresented populations typically studied in wellness, accessibility, and aging. However such datasets are scarce and in this paper we highlight challenges for sharing or locating them.  They tend to come from smaller samples having highly variable charac-teristics, require expert annotators, and pose more prominent privacy risks.  We discuss sharing practices as they pertain to specific user groups, access methods, and licensing.  Our analysis is based on 140 datasets that were manually located across different sources: 56 available publicly, 31 available upon request, and 53 unshared but described in manuscripts. To promote discovery and transparency, all datasets are described at IncluSet, our new data surfacing repository.},
year = {2020},
booktitle = {NeurIPS 2020 Workshop on Dataset Curation and Security },
series = {NeurIPS '20}
}


@inproceedings{codesign,
author = {\textbf{(Under review) Utkarsh, Dwivedi} and Merijke Coenraad and Jonggi Hong and Jaina Gandhi and Raj A Parikh and Ghazaleh Keshavarz and Elizabeth Bonsignore and Hernisa Kacorri},
title = {Co-designing Teachable Machines with Children},
year = {2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the  24th ACM Conference on Computer-Supported Cooperative Work and Social Computing},
location = {Virtual Event},
series = {CSCW 21}
}

@inproceedings{10.1145/3025171.3025202,
img={/assets/img/optidwell.png},
selected={true},
pdf={https://drive.google.com/open?id=0B4aeN-cePkCBaVJPS1lERi1UZ0E},
author = {Nayyar, Aanand and Dwivedi, Utkarsh and Ahuja, Karan and Rajput, Nitendra and Nagar, Seema and Dey, Kuntal},
title = {OptiDwell: Intelligent Adjustment of Dwell Click Time},
year = {2017},
isbn = {9781450343480},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025171.3025202},
doi = {10.1145/3025171.3025202},
abstract = {Gaze based navigation with digital screens offer a hands-free and touchless interaction, which is often useful in providing a hygienic interaction experience in a public kiosk scenario. The goodness of such a navigation system depends not only on the accuracy of detecting the eye gaze but also on the ability to determine whether a user is interested in clicking a button or is just looking at the button. The time for which a user needs to gaze at a particular button before it is considered as a click action is called the dwell time. In this paper, we explore intelligent adjustment of dwell times, where mouse click events on the buttons of a given application are emulated with user gaze. A constant dwell-time for all buttons and for all users may not provide an efficient and intuitive interface. We thereby propose a model to dynamically adjust dwell-time values used to emulate user mouse click events, exploiting the user's experience with different portions of a given application. The adjustment happens at a per-user, per-button granularity, as a function of the user's (a) prior usage experience of the given button within the application and (b) Midas touch characteristics for the given button. We propose OptiDwell, inspired by the action-value method based solutions to the Multi-Armed Bandits problem, for dwell click time adaptation. We experiment OptiDwell using an interactive TV channel browsing interface application, constituting of a mix of text and image buttons, over 10 computer-savvy users generating over 9000 click tasks. We observe significant improvement of user comfort level over the sessions, quantified by (a) improved (reduced) dwell times and (b) reduced number of Midas touches in spite of faster dwell-clicks, as high as 10-fold reduction in the best case. Our work is useful for creating an interface, with accurate, fast and comfortable dwell-clicks for each interface element (e.g., buttons), and each user.},
booktitle = {Proceedings of the 2017 International Conference on Intelligent User Interfaces},
pages = {193–204},
numpages = {12},
keywords = {adaptive dwell time, dwell click, gaze tracking, midas touch},
location = {Limassol, Cyprus},
series = {IUI '17}
}

@inproceedings{10.1145/3030024.3040989,
img={/assets/img/visualmath.png},
selected={true},
pdf={https://drive.google.com/open?id=0B4aeN-cePkCBN2wteFYtZ29HUWM},
author = {Dwivedi, Utkarsh and Rajput, Nitendra and Dey, Prasenjit and Varkey, Blessin},
title = {VisualMath: An Automated Visualization System for Understanding Math Word-Problems},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org/10.1145/3030024.3040989},
doi = {10.1145/3030024.3040989},
abstract = {Math word problems are difficult for students to start with since they involve understanding the problem?s context and abstracting out its underlying mathematical operations. A visual understanding of the problem at hand can be very useful for the comprehension of the problem. We present a system VisualMath that uses machine learning tools and crafted visual logic to automatically generate appropriate visualizations from the text of the word-problems and solve it. We demonstrate the improvements in the understanding of math word-problems by conducting a user study and learning of meaning of relevant new words by students.},
booktitle = {Proceedings of the 2017 International Conference on Intelligent User Interfaces Companion},
pages = {105–108},
numpages = {4},
keywords = {natural language processing, automated visualization},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}


@inproceedings{10.1145/2830629.2835223,
img={/assets/img/compliance.png},
author = {Dwivedi, Utkarsh and  Dasgupta, Anirban},
title = {Enabling Compliance of Environmental Conditions},
year = {2015},
isbn = {9781450334907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org/10.1145/2830629.2835223},
doi = {10.1145/2830629.2835223},
abstract = {Industrial projects in India have to agree to specific sets of environmental conditions in order to function. Lack of compliance with these conditions results both in irreversible damage to the local environment as well as conflicts among the industry and the local community. Our aim is to provide a system that raises general awareness in the local community about the environmental conditions in vogue among the nearby industries so that compliance violations can be reported early on. We outline work in progress to mine the text of the clearance conditions and build a searchable mapping system that can answer various queries about these conditions.},
booktitle = {Proceedings of the 2015 Annual Symposium on Computing for Development},
pages = {79–80},
numpages = {2},
keywords = {latent dirichlet allocation, environmental compliance, text mining},
location = {London, United Kingdom},
series = {DEV '15}
}

@article{sharma2018using,
  title={Using a Common Sense Knowledge Base to Auto Generate Multi-Dimensional Vocabulary Assessments.},
  author={Sharma Mittal, Ruhi and Nagar, Seema and Sharma, Mourvi and Dwivedi, Utkarsh and Dey, Prasenjit and Kokku, Ravi},
  journal={International Educational Data Mining Society},
  year={2018},
  publisher={ERIC}
}
